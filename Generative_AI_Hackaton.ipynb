{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadMudassirRaza12345/Generative_AI_hackton/blob/main/Generative_AI_Hackaton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1IQs3PKvl1uG",
        "outputId": "9c3b7655-d9e1-4acc-a273-7f5f7396364f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting clarifai\n",
            "  Downloading clarifai-10.0.0-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.2/135.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting clarifai-grpc~=10.0.1 (from clarifai)\n",
            "  Downloading clarifai_grpc-10.0.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from clarifai) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from clarifai) (1.23.5)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from clarifai) (4.66.1)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.68 in /usr/local/lib/python3.10/dist-packages (from clarifai) (4.8.0.76)\n",
            "Collecting tritonclient>=2.34.0 (from clarifai)\n",
            "  Downloading tritonclient-2.41.1-py3-none-manylinux1_x86_64.whl (12.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich>=13.4.2 in /usr/local/lib/python3.10/dist-packages (from clarifai) (13.7.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from clarifai) (6.0.1)\n",
            "Collecting schema>=0.7.5 (from clarifai)\n",
            "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
            "Collecting Pillow>=9.5.0 (from clarifai)\n",
            "  Downloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index>=0.9.27 (from clarifai)\n",
            "  Downloading llama_index-0.9.31-py3-none-any.whl (15.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf>=3.17.4 (from clarifai)\n",
            "  Downloading pypdf-3.17.4-py3-none-any.whl (278 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.44.0 in /usr/local/lib/python3.10/dist-packages (from clarifai-grpc~=10.0.1->clarifai) (1.60.0)\n",
            "Requirement already satisfied: protobuf>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from clarifai-grpc~=10.0.1->clarifai) (3.20.3)\n",
            "Requirement already satisfied: googleapis-common-protos>=1.53.0 in /usr/local/lib/python3.10/dist-packages (from clarifai-grpc~=10.0.1->clarifai) (1.62.0)\n",
            "Requirement already satisfied: requests>=2.25.1 in /usr/local/lib/python3.10/dist-packages (from clarifai-grpc~=10.0.1->clarifai) (2.31.0)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.27->clarifai) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.27->clarifai) (3.9.1)\n",
            "Collecting beautifulsoup4<5.0.0,>=4.12.2 (from llama-index>=0.9.27->clarifai)\n",
            "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses-json (from llama-index>=0.9.27->clarifai)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index>=0.9.27->clarifai)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.27->clarifai) (2023.6.0)\n",
            "Collecting httpx (from llama-index>=0.9.27->clarifai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.27->clarifai) (1.5.8)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.27->clarifai) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.27->clarifai) (3.8.1)\n",
            "Collecting openai>=1.1.0 (from llama-index>=0.9.27->clarifai)\n",
            "  Downloading openai-1.7.2-py3-none-any.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.1/212.1 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.27->clarifai) (8.2.3)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index>=0.9.27->clarifai)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.27->clarifai) (4.5.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index>=0.9.27->clarifai)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->clarifai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->clarifai) (2023.3.post1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.4.2->clarifai) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.4.2->clarifai) (2.16.1)\n",
            "Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.10/dist-packages (from schema>=0.7.5->clarifai) (21.6.0)\n",
            "Collecting python-rapidjson>=0.9.1 (from tritonclient>=2.34.0->clarifai)\n",
            "  Downloading python_rapidjson-1.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index>=0.9.27->clarifai) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index>=0.9.27->clarifai) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index>=0.9.27->clarifai) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index>=0.9.27->clarifai) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index>=0.9.27->clarifai) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index>=0.9.27->clarifai) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->llama-index>=0.9.27->clarifai) (2.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama-index>=0.9.27->clarifai) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.4.2->clarifai) (0.1.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index>=0.9.27->clarifai) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index>=0.9.27->clarifai) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index>=0.9.27->clarifai) (2023.6.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index>=0.9.27->clarifai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index>=0.9.27->clarifai) (1.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index>=0.9.27->clarifai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index>=0.9.27->clarifai) (1.3.0)\n",
            "Collecting typing-extensions>=4.5.0 (from llama-index>=0.9.27->clarifai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index>=0.9.27->clarifai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx->llama-index>=0.9.27->clarifai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index>=0.9.27->clarifai) (3.6)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index>=0.9.27->clarifai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.3.5->clarifai) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->clarifai-grpc~=10.0.1->clarifai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->clarifai-grpc~=10.0.1->clarifai) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index>=0.9.27->clarifai) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index>=0.9.27->clarifai)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index>=0.9.27->clarifai)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index>=0.9.27->clarifai) (1.2.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index>=0.9.27->clarifai) (23.2)\n",
            "Installing collected packages: typing-extensions, schema, python-rapidjson, pypdf, Pillow, mypy-extensions, marshmallow, h11, deprecated, beautifulsoup4, typing-inspect, tritonclient, tiktoken, httpcore, clarifai-grpc, httpx, dataclasses-json, openai, llama-index, clarifai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.11.2\n",
            "    Uninstalling beautifulsoup4-4.11.2:\n",
            "      Successfully uninstalled beautifulsoup4-4.11.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.2.0 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-10.2.0 beautifulsoup4-4.12.2 clarifai-10.0.0 clarifai-grpc-10.0.3 dataclasses-json-0.6.3 deprecated-1.2.14 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 llama-index-0.9.31 marshmallow-3.20.2 mypy-extensions-1.0.0 openai-1.7.2 pypdf-3.17.4 python-rapidjson-1.14 schema-0.7.5 tiktoken-0.5.2 tritonclient-2.41.1 typing-extensions-4.9.0 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install clarifai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMI-PlRCEWgz",
        "outputId": "b333f858-0b67-4be1-ea4f-d6240766cf24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (10.2.0)\n"
          ]
        }
      ],
      "source": [
        "pip install Pillow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_rMvq4iEXKG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmeF38NHmMPY",
        "outputId": "6f9bc489-a135-4b0e-80ab-4da3bc82ab15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CLARIFAI_PAT=0611f7f319234e9582b70cedb6d3d95d\n"
          ]
        }
      ],
      "source": [
        "%env CLARIFAI_PAT = 0611f7f319234e9582b70cedb6d3d95d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3QOh4rVamzxd"
      },
      "outputs": [],
      "source": [
        "from clarifai.client.model import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "i-D8Zf8AFrLS",
        "outputId": "e9625816-9548-44cf-a6ec-93a39819bfee"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 17&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">17</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/PIL/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Image.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3309</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">open</span>                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3306 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> message <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> accept_warnings:                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3307 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>warnings.warn(message)                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3308 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>msg = <span style=\"color: #808000; text-decoration-color: #808000\">\"cannot identify image file %r\"</span> % (filename <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> filename <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> fp)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3309 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> UnidentifiedImageError(msg)                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3310 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3311 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3312 #</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">UnidentifiedImageError: </span>cannot identify image file <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">_io.BytesIO</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x78ee8a1ee930</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 17>\u001b[0m:\u001b[94m17\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/PIL/\u001b[0m\u001b[1;33mImage.py\u001b[0m:\u001b[94m3309\u001b[0m in \u001b[92mopen\u001b[0m                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m3306 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m message \u001b[95min\u001b[0m accept_warnings:                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m3307 \u001b[0m\u001b[2m│   │   \u001b[0mwarnings.warn(message)                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m3308 \u001b[0m\u001b[2m│   \u001b[0mmsg = \u001b[33m\"\u001b[0m\u001b[33mcannot identify image file \u001b[0m\u001b[33m%r\u001b[0m\u001b[33m\"\u001b[0m % (filename \u001b[94mif\u001b[0m filename \u001b[94melse\u001b[0m fp)                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3309 \u001b[2m│   \u001b[0m\u001b[94mraise\u001b[0m UnidentifiedImageError(msg)                                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m3310 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m3311 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m3312 \u001b[0m\u001b[2m#\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mUnidentifiedImageError: \u001b[0mcannot identify image file \u001b[1m<\u001b[0m\u001b[1;95m_io.BytesIO\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x78ee8a1ee930\u001b[0m\u001b[1m>\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# from PIL import Image\n",
        "# from io import BytesIO\n",
        "# from clarifai.client.model import Model\n",
        "# import base64\n",
        "\n",
        "# prompt = \"A cozy cabin in the woods surrounded by colorful autumn leaves\"\n",
        "\n",
        "\n",
        "# inference_params = dict(quality=\"standard\", size= '1024x1024')\n",
        "\n",
        "# # Model Predict\n",
        "# model_prediction = Model(\"https://clarifai.com/openai/dall-e/models/dall-e-3\").predict_by_bytes(prompt.encode(), input_type=\"text\", inference_params=inference_params)\n",
        "\n",
        "# output_base64 = model_prediction.outputs[0].data.image.base64\n",
        "\n",
        "# image_data = base64.b64decode(output_base64)\n",
        "# image = Image.open(BytesIO(image_data))\n",
        "\n",
        "# # Display the image\n",
        "# image.show()\n",
        "# # with open('image.png', 'wb') as f:\n",
        "# #     f.write(output_base64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78QrO1IkJeGv"
      },
      "outputs": [],
      "source": [
        "from io import BytesIO\n",
        "from clarifai.client.model import Model\n",
        "from PIL import Image\n",
        "import base64\n",
        "\n",
        "prompt = \"A cozy cabin in the woods surrounded by colorful autumn leaves\"\n",
        "\n",
        "inference_params = dict(quality=\"standard\", size='1024x1024')\n",
        "\n",
        "# Model Predict\n",
        "model_prediction = Model(\"https://clarifai.com/openai/dall-e/models/dall-e-3\").predict_by_bytes(prompt.encode(), input_type=\"text\", inference_params=inference_params)\n",
        "\n",
        "output_base64 = model_prediction.outputs[0].data.image.base64\n",
        "\n",
        "with open('image.png', 'wb') as f:\n",
        "    f.write(output_base64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "O1xfO_Tzo0F4",
        "outputId": "3b7f6266-5602-4803-b29f-e798a913862e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 9&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">9</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/clarifai/client/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">model.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">490</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predict_by_bytes</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">487 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> input_type == <span style=\"color: #808000; text-decoration-color: #808000\">\"audio\"</span>:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">488 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>input_proto = Inputs.get_input_from_bytes(<span style=\"color: #808000; text-decoration-color: #808000\">\"\"</span>, audio_bytes=input_bytes)               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">489 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>490 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.predict(                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">491 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>inputs=[input_proto], inference_params=inference_params, output_config=output_co   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">492 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">493 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predict_by_url</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>,                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/clarifai/client/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">model.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">414</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predict</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">411 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">continue</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">412 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">413 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> response.status.code != status_code_pb2.SUCCESS:                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>414 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">Exception</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Model Predict failed with response {</span>response.status<span style=\"color: #808000; text-decoration-color: #808000\">!r}\"</span>)         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">415 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">416 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">break</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">417 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Exception: </span>Model Predict failed with response code: MODEL_PREDICTION_FAILED\n",
              "description: <span style=\"color: #008000; text-decoration-color: #008000\">\"Model prediction failed\"</span>\n",
              "details: <span style=\"color: #008000; text-decoration-color: #008000\">\"OpenAI API Error: BadRequestError-Error code: 400 - {\\'error\\': {\\'code\\': \\'content_policy_violation\\', </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">\\'message\\': \\'Your request was rejected as a result of our safety system. Your prompt may contain text that is not</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">allowed by our safety system.\\', \\'param\\': None, \\'type\\': \\'invalid_request_error\\'}}\"</span>\n",
              "req_id: <span style=\"color: #008000; text-decoration-color: #008000\">\"637f0267c59155e9abbd9cef38b72a0a\"</span>\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 9>\u001b[0m:\u001b[94m9\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/clarifai/client/\u001b[0m\u001b[1;33mmodel.py\u001b[0m:\u001b[94m490\u001b[0m in \u001b[92mpredict_by_bytes\u001b[0m         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m487 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m input_type == \u001b[33m\"\u001b[0m\u001b[33maudio\u001b[0m\u001b[33m\"\u001b[0m:                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m488 \u001b[0m\u001b[2m│     \u001b[0minput_proto = Inputs.get_input_from_bytes(\u001b[33m\"\u001b[0m\u001b[33m\"\u001b[0m, audio_bytes=input_bytes)               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m489 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m490 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.predict(                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m491 \u001b[0m\u001b[2m│   │   \u001b[0minputs=[input_proto], inference_params=inference_params, output_config=output_co   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m492 \u001b[0m\u001b[2m  \u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m493 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mpredict_by_url\u001b[0m(\u001b[96mself\u001b[0m,                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/clarifai/client/\u001b[0m\u001b[1;33mmodel.py\u001b[0m:\u001b[94m414\u001b[0m in \u001b[92mpredict\u001b[0m                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m411 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mcontinue\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m412 \u001b[0m\u001b[2m│     \u001b[0m                                                                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m413 \u001b[0m\u001b[2m│     \u001b[0m\u001b[94mif\u001b[0m response.status.code != status_code_pb2.SUCCESS:                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m414 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mException\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mModel Predict failed with response \u001b[0m\u001b[33m{\u001b[0mresponse.status\u001b[33m!r}\u001b[0m\u001b[33m\"\u001b[0m)         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m415 \u001b[0m\u001b[2m│     \u001b[0m\u001b[94melse\u001b[0m:                                                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m416 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mbreak\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m417 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mException: \u001b[0mModel Predict failed with response code: MODEL_PREDICTION_FAILED\n",
              "description: \u001b[32m\"Model prediction failed\"\u001b[0m\n",
              "details: \u001b[32m\"OpenAI API Error: BadRequestError-Error code: 400 - \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'error\\': \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'code\\': \\'content_policy_violation\\', \u001b[0m\n",
              "\u001b[32m\\'message\\': \\'Your request was rejected as a result of our safety system. Your prompt may contain text that is not\u001b[0m\n",
              "\u001b[32mallowed by our safety system.\\', \\'param\\': None, \\'type\\': \\'invalid_request_error\\'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\"\u001b[0m\n",
              "req_id: \u001b[32m\"637f0267c59155e9abbd9cef38b72a0a\"\u001b[0m\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# https://clarifai.com/openai/dall-e/models/dall-e-3\n",
        "#Image Generation DALL-E API\n",
        "prompt = \"Cat eat the dog\"\n",
        "\n",
        "\n",
        "inference_params = dict(quality=\"standard\", size= '1024x1024')\n",
        "\n",
        "# Model Predict\n",
        "model_prediction = Model(\"https://clarifai.com/openai/dall-e/models/dall-e-3\").predict_by_bytes(prompt.encode(), input_type=\"text\", inference_params=inference_params)\n",
        "\n",
        "output_base64 = model_prediction.outputs[0].data.image.base64\n",
        "print(output_base64)\n",
        "with open('image1.png', 'wb') as f:\n",
        "    f.write(output_base64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wy8NbxGott04"
      },
      "outputs": [],
      "source": [
        "# from clarifai.client.model import Model\n",
        "\n",
        "# prompt = \"What’s the future of AI?\"\n",
        "\n",
        "# openai_api_key = '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'\n",
        "\n",
        "# inference_params = dict(temperature=0.2, max_tokens=100, api_key = openai_api_key)\n",
        "\n",
        "# # Model Predict\n",
        "# model_prediction = Model(\"https://clarifai.com/openai/chat-completion/models/gpt-4-turbo\").predict_by_bytes(prompt.encode(), input_type=\"text\", inference_params=inference_params)\n",
        "\n",
        "# print(model_prediction.outputs[0].data.text.raw)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YviANc8gDJAT"
      },
      "source": [
        "# New section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "Q84wkL3dV3Ww",
        "outputId": "12dea981-7e97-4936-e1af-dba89a9ad26b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 14&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">14</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/clarifai/client/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">model.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">490</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predict_by_bytes</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">487 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> input_type == <span style=\"color: #808000; text-decoration-color: #808000\">\"audio\"</span>:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">488 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>input_proto = Inputs.get_input_from_bytes(<span style=\"color: #808000; text-decoration-color: #808000\">\"\"</span>, audio_bytes=input_bytes)               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">489 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>490 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.predict(                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">491 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>inputs=[input_proto], inference_params=inference_params, output_config=output_co   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">492 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">493 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predict_by_url</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>,                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/clarifai/client/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">model.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">414</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predict</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">411 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">continue</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">412 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">413 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> response.status.code != status_code_pb2.SUCCESS:                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>414 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">Exception</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Model Predict failed with response {</span>response.status<span style=\"color: #808000; text-decoration-color: #808000\">!r}\"</span>)         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">415 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">416 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">break</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">417 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Exception: </span>Model Predict failed with response code: MODEL_PREDICTION_FAILED\n",
              "description: <span style=\"color: #008000; text-decoration-color: #008000\">\"Model prediction failed\"</span>\n",
              "details: <span style=\"color: #008000; text-decoration-color: #008000\">\"OpenAI API Error: BadRequestError-Error code: 400 - {\\'error\\': {\\'message\\': \\\"1 validation error for </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">Request\\\\nbody -&gt; voice\\\\n  value is not a valid enumeration member; permitted: \\'nova\\', \\'shimmer\\', \\'echo\\', </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">\\'onyx\\', \\'fable\\', \\'alloy\\' (type=type_error.enum; enum_values=[&lt;Voice.NOVA: \\'nova\\'&gt;, &lt;Voice.SHIMMER: </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">\\'shimmer\\'&gt;, &lt;Voice.ECHO: \\'echo\\'&gt;, &lt;Voice.ONYX: \\'onyx\\'&gt;, &lt;Voice.FABLE: \\'fable\\'&gt;, &lt;Voice.ALLOY: </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">\\'alloy\\'&gt;])\\\", \\'type\\': \\'invalid_request_error\\', \\'param\\': None, \\'code\\': None}}\"</span>\n",
              "req_id: <span style=\"color: #008000; text-decoration-color: #008000\">\"8b2895c82a2a712144e16219d8940fab\"</span>\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 14>\u001b[0m:\u001b[94m14\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/clarifai/client/\u001b[0m\u001b[1;33mmodel.py\u001b[0m:\u001b[94m490\u001b[0m in \u001b[92mpredict_by_bytes\u001b[0m         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m487 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m input_type == \u001b[33m\"\u001b[0m\u001b[33maudio\u001b[0m\u001b[33m\"\u001b[0m:                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m488 \u001b[0m\u001b[2m│     \u001b[0minput_proto = Inputs.get_input_from_bytes(\u001b[33m\"\u001b[0m\u001b[33m\"\u001b[0m, audio_bytes=input_bytes)               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m489 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m490 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.predict(                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m491 \u001b[0m\u001b[2m│   │   \u001b[0minputs=[input_proto], inference_params=inference_params, output_config=output_co   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m492 \u001b[0m\u001b[2m  \u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m493 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mpredict_by_url\u001b[0m(\u001b[96mself\u001b[0m,                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/clarifai/client/\u001b[0m\u001b[1;33mmodel.py\u001b[0m:\u001b[94m414\u001b[0m in \u001b[92mpredict\u001b[0m                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m411 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mcontinue\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m412 \u001b[0m\u001b[2m│     \u001b[0m                                                                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m413 \u001b[0m\u001b[2m│     \u001b[0m\u001b[94mif\u001b[0m response.status.code != status_code_pb2.SUCCESS:                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m414 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mException\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mModel Predict failed with response \u001b[0m\u001b[33m{\u001b[0mresponse.status\u001b[33m!r}\u001b[0m\u001b[33m\"\u001b[0m)         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m415 \u001b[0m\u001b[2m│     \u001b[0m\u001b[94melse\u001b[0m:                                                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m416 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mbreak\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m417 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mException: \u001b[0mModel Predict failed with response code: MODEL_PREDICTION_FAILED\n",
              "description: \u001b[32m\"Model prediction failed\"\u001b[0m\n",
              "details: \u001b[32m\"OpenAI API Error: BadRequestError-Error code: 400 - \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'error\\': \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'message\\': \\\"1 validation error for \u001b[0m\n",
              "\u001b[32mRequest\\\\nbody -> voice\\\\n  value is not a valid enumeration member; permitted: \\'nova\\', \\'shimmer\\', \\'echo\\', \u001b[0m\n",
              "\u001b[32m\\'onyx\\', \\'fable\\', \\'alloy\\' \u001b[0m\u001b[32m(\u001b[0m\u001b[32mtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtype_error\u001b[0m\u001b[32m.enum; \u001b[0m\u001b[32menum_values\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m<\u001b[0m\u001b[32mVoice.NOVA:\u001b[0m\u001b[32m \\'nova\\'>, <Voice.SHIMMER: \u001b[0m\n",
              "\u001b[32m\\'shimmer\\'>, <Voice.ECHO: \\'echo\\'>, <Voice.ONYX: \\'onyx\\'>, <Voice.FABLE: \\'fable\\'>, <Voice.ALLOY: \u001b[0m\n",
              "\u001b[32m\\'alloy\\'\u001b[0m\u001b[32m>\u001b[0m\u001b[32m]\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\", \\'type\\': \\'invalid_request_error\\', \\'param\\': None, \\'code\\': None\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\"\u001b[0m\n",
              "req_id: \u001b[32m\"8b2895c82a2a712144e16219d8940fab\"\u001b[0m\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# # https://clarifai.com/openai/tts/models/openai-tts-1\n",
        "# # Text-to-Speech model\n",
        "\n",
        "# from clarifai.client.model import Model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDeKDsRrEneF"
      },
      "outputs": [],
      "source": [
        "# # GPT-4 vision\n",
        "# # image upload it give it summary\n",
        "# from clarifai.client.model import Model\n",
        "\n",
        "# prompt = \"What’s in this image?\"\n",
        "\n",
        "# image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
        "\n",
        "\n",
        "\n",
        "# inference_params = dict(temperature=0.2, max_tokens=100, image_url=image_url)\n",
        "\n",
        "# # Model Predict\n",
        "# model_prediction = Model(\"https://clarifai.com/openai/chat-completion/models/gpt-4-vision\").predict_by_bytes(prompt.encode(), input_type=\"text\", inference_params=inference_params)\n",
        "# print(model_prediction.outputs[0].data.text.raw)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4SwsVm5PiaZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# prompt = \"What’s the future of AI?\"\n",
        "\n",
        "\n",
        "\n",
        "# inference_params = dict(temperature=0.2, max_tokens=100)\n",
        "\n",
        "# # Model Predict\n",
        "# model_prediction = Model(\"https://clarifai.com/openai/chat-completion/models/gpt-4-turbo\").predict_by_bytes(prompt.encode(), input_type=\"text\", inference_params=inference_params)\n",
        "\n",
        "# print(model_prediction.outputs[0].data.text.raw)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQDFLndqcD_U",
        "outputId": "b0a0d2bf-c36f-4ef4-c3a5-3fbf1152e5d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your creative prompt: Romantic weather enjoying\n",
            "\n",
            "Generated GPT Text:\n",
            "Weather can play a significant role in creating a romantic atmosphere. Certain weather conditions are often associated with romance. Here are a few scenarios where weather can enhance the romantic mood:\n",
            "\n",
            "1. **Rainy Days**: The sound of raindrops, the cool, fresh air, and the feeling of coziness can make rainy days unexpectedly romantic. Couples might enjoy staying in, cuddling under a blanket, and watching movies or listening to the rain together.\n",
            "\n",
            "2. **Sunset**: Watching the sunset together is a classic romantic activity. The beautiful colors and the calmness of the evening can be very intimate and provide a perfect backdrop for a romantic moment.\n",
            "\n",
            "3. **Starry Nights**: A clear night sky filled with stars offers a sense of wonder and can be\n",
            "\n",
            "Generated DALL-E Image:\n",
            "Image URL: image.png\n",
            "\n",
            "Generated TTS Audio:\n",
            "Audio URL: output_audio.wav\n"
          ]
        }
      ],
      "source": [
        "from clarifai.client.model import Model\n",
        "\n",
        "\n",
        "def generate_gpt(prompt):\n",
        "    # Use GPT-4 Turbo for prompt completion\n",
        "    prompt=f\"You are Marketing Specialist.Base on user description and content \"\n",
        "    inference_params = dict(temperature=0.2, max_tokens=150)\n",
        "    model_prediction = Model(\"https://clarifai.com/openai/chat-completion/models/gpt-4-turbo\").predict_by_bytes(prompt.encode(), input_type=\"text\", inference_params=inference_params)\n",
        "    return model_prediction.outputs[0].data.text.raw\n",
        "\n",
        "\n",
        "def generate_dalle_image(prompt):\n",
        "#     # Use DALL-E API to generate an image based on the prompt\n",
        "    prompt = f\"Imagine you are a skilled marketing specialist. Base on the given user description and content, devise a creative and effective social media campaign strategy for a new product launch: {prompt}\"\n",
        "    inference_params = dict(quality=\"standard\", size='1024x1024')\n",
        "    model_prediction = Model(\"https://clarifai.com/openai/dall-e/models/dall-e-3\").predict_by_bytes(prompt.encode(), input_type=\"text\", inference_params=inference_params)\n",
        "    output_base64 = model_prediction.outputs[0].data.image.base64\n",
        "    with open('image.png', 'wb') as f:\n",
        "      f.write(output_base64)\n",
        "    return \"image.png\"\n",
        "\n",
        "\n",
        "def generate_tts_audio(text):\n",
        "    # Use Text-to-Speech API to convert text to audio\n",
        "    inference_params = dict(voice=\"alloy\", speed=1.0 )\n",
        "    model_prediction = Model(\"https://clarifai.com/openai/tts/models/openai-tts-1\").predict_by_bytes(text.encode(), input_type=\"text\", inference_params=inference_params)\n",
        "    output_base64 = model_prediction.outputs[0].data.audio.base64\n",
        "    with open('output_audio.wav', 'wb') as f:\n",
        "      f.write(output_base64)\n",
        "    return 'output_audio.wav'\n",
        "\n",
        "def main():\n",
        "    # User input\n",
        "    user_prompt = input(\"Enter your creative prompt: \")\n",
        "\n",
        "    # Generate GPT text\n",
        "    gpt_output = generate_gpt(user_prompt)\n",
        "\n",
        "    # Generate DALL-E image\n",
        "    dalle_image_url = generate_dalle_image(user_prompt)\n",
        "\n",
        "    # Generate TTS audio\n",
        "    tts_audio_url = generate_tts_audio(gpt_output)\n",
        "\n",
        "    print(\"\\nGenerated GPT Text:\")\n",
        "    print(gpt_output)\n",
        "\n",
        "    print(\"\\nGenerated DALL-E Image:\")\n",
        "    print(f\"Image URL: {dalle_image_url}\")\n",
        "\n",
        "    print(\"\\nGenerated TTS Audio:\")\n",
        "    print(f\"Audio URL: {tts_audio_url}\")\n",
        "\n",
        "main()\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jhEoCk3Z9ro",
        "outputId": "72de1a1a-9ea2-4e55-d027-5fbe8cb03bc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your creative prompt: You are a graphic designer .Now create a post for company name Marketlytics . They have voccancy of data engineer \n",
            "\n",
            "Generated GPT Text:\n",
            "I'm sorry, but I can't assist with that request.\n",
            "\n",
            "Generated DALL-E Image:\n",
            "Image URL: image.png\n",
            "\n",
            "Generated TTS Audio:\n",
            "Audio URL: output_audio.wav\n"
          ]
        }
      ],
      "source": [
        "from clarifai.client.model import Model\n",
        "from clarifai.client.input import Inputs\n",
        "\n",
        "def generate_gpt(img_loc):\n",
        "    # Use GPT-4 Vision for image analysis\n",
        "    IMAGE_FILE_LOCATION =  img_loc\n",
        "    with open(IMAGE_FILE_LOCATION, \"rb\") as f:\n",
        "      file_bytes = f.read()\n",
        "    #prompt = f\"Put yourself in the shoes of a marketing specialist. Analyze the following image created for audience engagement. Envision how this image could tell a captivating story, evoke emotions, and encourage audience interaction. Consider the visual elements, color schemes, and overall composition. Your insights will shape the content that enhances the image's impact and resonates with the audience\"\n",
        "    prompt='Analyze the content of this image and write a creative, engaging story that brings the scene to life. Describe the characters, setting, and actions in a way that would captivate a young audience'\n",
        "    inference_params = dict(temperature=0.2, max_tokens=100)\n",
        "    model_prediction = Model(\"https://clarifai.com/openai/chat-completion/models/openai-gpt-4-vision\").predict(inputs = [Inputs.get_multimodal_input(input_id=\"\", image_bytes = file_bytes, raw_text=prompt)], inference_params=inference_params)\n",
        "    return model_prediction.outputs[0].data.text.raw\n",
        "\n",
        "\n",
        "\n",
        "def generate_dalle_image(user_description):\n",
        "#     # Use DALL-E API to generate an image based on the prompt\n",
        "    prompt = f\"Imagine you are a skilled marketing specialist. Base on the given user description and content, devise a creative and effective social media campaign strategy for a new product launch: {user_description}\"\n",
        "    inference_params = dict(quality=\"standard\", size='1024x1024')\n",
        "    model_prediction = Model(\"https://clarifai.com/openai/dall-e/models/dall-e-3\").predict_by_bytes(prompt.encode(), input_type=\"text\", inference_params=inference_params)\n",
        "    output_base64 = model_prediction.outputs[0].data.image.base64\n",
        "    with open('image.png', 'wb') as f:\n",
        "      f.write(output_base64)\n",
        "    return \"image.png\"\n",
        "\n",
        "\n",
        "def generate_tts_audio(text):\n",
        "    # Use Text-to-Speech API to convert text to audio\n",
        "    inference_params = dict(voice=\"echo\", speed=1.0 )\n",
        "    model_prediction = Model(\"https://clarifai.com/openai/tts/models/openai-tts-1\").predict_by_bytes(text.encode(), input_type=\"text\", inference_params=inference_params)\n",
        "    output_base64 = model_prediction.outputs[0].data.audio.base64\n",
        "    with open('output_audio.wav', 'wb') as f:\n",
        "      f.write(output_base64)\n",
        "    return 'output_audio.wav'\n",
        "\n",
        "def main():\n",
        "    # User input\n",
        "    user_prompt = input(\"Enter your creative prompt: \")\n",
        "\n",
        "    # Generate DALL-E image\n",
        "    dalle_image_url = generate_dalle_image(user_prompt)\n",
        "\n",
        "    # Generate GPT text\n",
        "    gpt_output = generate_gpt(dalle_image_url)\n",
        "\n",
        "    # Generate TTS audio\n",
        "    tts_audio_url = generate_tts_audio(gpt_output)\n",
        "\n",
        "    print(\"\\nGenerated GPT Text:\")\n",
        "    print(gpt_output)\n",
        "\n",
        "    print(\"\\nGenerated DALL-E Image:\")\n",
        "    print(f\"Image URL: {dalle_image_url}\")\n",
        "\n",
        "    print(\"\\nGenerated TTS Audio:\")\n",
        "    print(f\"Audio URL: {tts_audio_url}\")\n",
        "\n",
        "main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acgT76o3bUsj"
      },
      "outputs": [],
      "source": [
        "def generate_gpt(img_loc):\n",
        "    # Use GPT-4 Vision for image analysis\n",
        "    IMAGE_FILE_LOCATION =  img_loc\n",
        "    with open(IMAGE_FILE_LOCATION, \"rb\") as f:\n",
        "      file_bytes = f.read()\n",
        "    prompt = f\"Put yourself in the shoes of a marketing specialist. Analyze the following image created for audience engagement. Envision how this image could tell a captivating story, evoke emotions, and encourage audience interaction. Consider the visual elements, color schemes, and overall composition. Your insights will shape the content that enhances the image's impact and resonates with the audience\"\n",
        "    inference_params = dict(temperature=0.2, max_tokens=100)\n",
        "    model_prediction = Model(\"https://clarifai.com/openai/chat-completion/models/openai-gpt-4-vision\").predict(inputs = [Inputs.get_multimodal_input(input_id=\"\", image_bytes = file_bytes, raw_text=prompt)], inference_params=inference_params)\n",
        "    return model_prediction.outputs[0].data.text.raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nbzHRiDcLm1"
      },
      "outputs": [],
      "source": [
        "gpt_output = generate_gpt('image.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fifVD8VGcYKP",
        "outputId": "3e4f783a-5c01-4379-8775-e258725f374e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "As a marketing specialist analyzing this image, I would note the following elements that could be used to engage an audience:\n",
            "\n",
            "1. Storytelling: The image presents a vibrant classroom setting filled with various activities. It appears to depict a teacher's work environment, showcasing educators in action and students engaged in learning. The story here could focus on the dedication of teachers and the dynamic nature of education. Marketing content could draw on themes of growth, learning, and the nurturing role of educators.\n",
            "\n",
            "2. Emotion: The classroom depicted is full of energy and positive interactions, which can evoke emotions such as nostalgia for one's own school days, admiration for the teaching profession, and hope for the future of education. Marketing messages could play on these emotions by highlighting the impact that teachers have on students' lives and the importance of supporting and valuing educators.\n",
            "\n",
            "3. Color Scheme: The image uses a warm and inviting color palette, with rich oranges, blues, and greens that give it a welcoming and optimistic feel. This choice of colors could be used to convey a sense of warmth, safety, and creativity that people often associate with the best learning environments. Marketing materials can echo this palette to create a cohesive visual identity.\n",
            "\n",
            "4. Composition: The image is carefully composed to draw the viewer's eye through the scene, from the teachers at the front to the various learning activities in the background. This level of detail can encourage viewers to spend more time engaging with the image, discovering new elements, and forming a deeper connection with the content. The marketing narrative could invite the audience to \"discover\" aspects of the education process they may not have considered before.\n",
            "\n",
            "5. Interaction: To encourage audience interaction, marketing content can ask viewers to share their own experiences with teachers who have made a difference in their lives, or to participate in discussions about the future of education. The image could be used as a prompt for storytelling contests, social media engagement, or educational campaigns that highlight the work of teachers.\n",
            "\n",
            "In conclusion, this image is rich with potential narratives and emotional hooks that can be leveraged to create compelling marketing content. The image celebrates education and could be used in various campaigns focused on teacher appreciation, educational innovation, or community engagement in schools.\n"
          ]
        }
      ],
      "source": [
        "print(gpt_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-GxkBSdSceaD",
        "outputId": "f555c779-e945-4708-a2a1-f7ca30084b10"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 6&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/clarifai/client/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">model.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">490</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predict_by_bytes</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">487 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> input_type == <span style=\"color: #808000; text-decoration-color: #808000\">\"audio\"</span>:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">488 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>input_proto = Inputs.get_input_from_bytes(<span style=\"color: #808000; text-decoration-color: #808000\">\"\"</span>, audio_bytes=input_bytes)               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">489 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>490 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.predict(                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">491 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>inputs=[input_proto], inference_params=inference_params, output_config=output_co   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">492 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">493 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predict_by_url</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>,                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/clarifai/client/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">model.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">414</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predict</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">411 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">continue</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">412 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">413 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> response.status.code != status_code_pb2.SUCCESS:                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>414 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">Exception</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Model Predict failed with response {</span>response.status<span style=\"color: #808000; text-decoration-color: #808000\">!r}\"</span>)         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">415 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">416 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">break</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">417 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Exception: </span>Model Predict failed with response code: MODEL_PREDICTION_FAILED\n",
              "description: <span style=\"color: #008000; text-decoration-color: #008000\">\"Model prediction failed\"</span>\n",
              "details: <span style=\"color: #008000; text-decoration-color: #008000\">\"OpenAI API Error: BadRequestError-Error code: 400 - {\\'error\\': {\\'message\\': \\\"1 validation error for </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">Request\\\\nbody -&gt; voice\\\\n  value is not a valid enumeration member; permitted: \\'nova\\', \\'shimmer\\', \\'echo\\', </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">\\'onyx\\', \\'fable\\', \\'alloy\\' (type=type_error.enum; enum_values=[&lt;Voice.NOVA: \\'nova\\'&gt;, &lt;Voice.SHIMMER: </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">\\'shimmer\\'&gt;, &lt;Voice.ECHO: \\'echo\\'&gt;, &lt;Voice.ONYX: \\'onyx\\'&gt;, &lt;Voice.FABLE: \\'fable\\'&gt;, &lt;Voice.ALLOY: </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">\\'alloy\\'&gt;])\\\", \\'type\\': \\'invalid_request_error\\', \\'param\\': None, \\'code\\': None}}\"</span>\n",
              "req_id: <span style=\"color: #008000; text-decoration-color: #008000\">\"0c8dddb579477e922ea90c7c51598a36\"</span>\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 6>\u001b[0m:\u001b[94m6\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/clarifai/client/\u001b[0m\u001b[1;33mmodel.py\u001b[0m:\u001b[94m490\u001b[0m in \u001b[92mpredict_by_bytes\u001b[0m         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m487 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m input_type == \u001b[33m\"\u001b[0m\u001b[33maudio\u001b[0m\u001b[33m\"\u001b[0m:                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m488 \u001b[0m\u001b[2m│     \u001b[0minput_proto = Inputs.get_input_from_bytes(\u001b[33m\"\u001b[0m\u001b[33m\"\u001b[0m, audio_bytes=input_bytes)               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m489 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m490 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.predict(                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m491 \u001b[0m\u001b[2m│   │   \u001b[0minputs=[input_proto], inference_params=inference_params, output_config=output_co   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m492 \u001b[0m\u001b[2m  \u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m493 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mpredict_by_url\u001b[0m(\u001b[96mself\u001b[0m,                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/clarifai/client/\u001b[0m\u001b[1;33mmodel.py\u001b[0m:\u001b[94m414\u001b[0m in \u001b[92mpredict\u001b[0m                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m411 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mcontinue\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m412 \u001b[0m\u001b[2m│     \u001b[0m                                                                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m413 \u001b[0m\u001b[2m│     \u001b[0m\u001b[94mif\u001b[0m response.status.code != status_code_pb2.SUCCESS:                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m414 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mException\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mModel Predict failed with response \u001b[0m\u001b[33m{\u001b[0mresponse.status\u001b[33m!r}\u001b[0m\u001b[33m\"\u001b[0m)         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m415 \u001b[0m\u001b[2m│     \u001b[0m\u001b[94melse\u001b[0m:                                                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m416 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mbreak\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m417 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mException: \u001b[0mModel Predict failed with response code: MODEL_PREDICTION_FAILED\n",
              "description: \u001b[32m\"Model prediction failed\"\u001b[0m\n",
              "details: \u001b[32m\"OpenAI API Error: BadRequestError-Error code: 400 - \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'error\\': \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'message\\': \\\"1 validation error for \u001b[0m\n",
              "\u001b[32mRequest\\\\nbody -> voice\\\\n  value is not a valid enumeration member; permitted: \\'nova\\', \\'shimmer\\', \\'echo\\', \u001b[0m\n",
              "\u001b[32m\\'onyx\\', \\'fable\\', \\'alloy\\' \u001b[0m\u001b[32m(\u001b[0m\u001b[32mtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtype_error\u001b[0m\u001b[32m.enum; \u001b[0m\u001b[32menum_values\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m<\u001b[0m\u001b[32mVoice.NOVA:\u001b[0m\u001b[32m \\'nova\\'>, <Voice.SHIMMER: \u001b[0m\n",
              "\u001b[32m\\'shimmer\\'>, <Voice.ECHO: \\'echo\\'>, <Voice.ONYX: \\'onyx\\'>, <Voice.FABLE: \\'fable\\'>, <Voice.ALLOY: \u001b[0m\n",
              "\u001b[32m\\'alloy\\'\u001b[0m\u001b[32m>\u001b[0m\u001b[32m]\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\", \\'type\\': \\'invalid_request_error\\', \\'param\\': None, \\'code\\': None\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\"\u001b[0m\n",
              "req_id: \u001b[32m\"0c8dddb579477e922ea90c7c51598a36\"\u001b[0m\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "input = \"I love your product very much\"\n",
        "\n",
        "inference_params = dict(voice=\"Echo\", speed=1.0)\n",
        "\n",
        "# Model Predict\n",
        "model_prediction = Model(\"https://clarifai.com/openai/tts/models/openai-tts-1\").predict_by_bytes(input.encode(), input_type=\"text\", inference_params=inference_params)\n",
        "\n",
        "output_base64 = model_prediction.outputs[0].data.audio.base64\n",
        "with open('output_audio1.wav', 'wb') as f:\n",
        "    f.write(output_base64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Dl-DaXhIi0Vk"
      },
      "outputs": [],
      "source": [
        "def generate_dalle_image(user_description):\n",
        "#     # Use DALL-E API to generate an image based on the prompt\n",
        "    prompt = f\"You are a Professional Graphic Designer.You have to Analyze the content and  create a post for social media Platform Like FacebooK ,Instagram , Linkedin etc In which write according to content :{user_description}\"\n",
        "    inference_params = dict(quality=\"standard\", size='1024x1024')\n",
        "    model_prediction = Model(\"https://clarifai.com/openai/dall-e/models/dall-e-3\").predict_by_bytes(prompt.encode(), input_type=\"text\", inference_params=inference_params)\n",
        "    output_base64 = model_prediction.outputs[0].data.image.base64\n",
        "    with open('image.png', 'wb') as f:\n",
        "      f.write(output_base64)\n",
        "\n",
        "\n",
        "def generate_gpt_turbo(prompt):\n",
        "    # Use GPT-4 Turbo for prompt completion\n",
        "    prompt=f\"You are a Professional Content writer.You have to create text content for any kind of job for Like FacebooK ,Instagram , Linkedin etc  according to :  {prompt}\"\n",
        "    inference_params = dict(temperature=0.2, max_tokens=150)\n",
        "    model_prediction = Model(\"https://clarifai.com/openai/chat-completion/models/gpt-4-turbo\").predict_by_bytes(prompt.encode(), input_type=\"text\", inference_params=inference_params)\n",
        "    return model_prediction.outputs[0].data.text.raw\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PEVX9aLLuTjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content_data=generate_gpt_turbo(\"I want to create a post for company name marketing.In the this post write the job open for data engineers. Fresh can also apply \")\n",
        "\n",
        "generate_dalle_image(content_data)\n",
        "\n",
        "print(content_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97pJqlZyuJsL",
        "outputId": "59cbe946-11e5-438a-d935-8411a5214392"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Certainly! Below is a sample social media post tailored for a company named \"Marketing Inc.\" that is looking to hire Data Engineers. This post is designed to be engaging and informative for platforms like LinkedIn, Facebook, and Instagram.\n",
            "\n",
            "---\n",
            "\n",
            "🚀 **Join Our Team at Marketing Inc.!** 🚀\n",
            "\n",
            "Are you passionate about data and looking to kickstart your career in a dynamic field? 📊✨ Marketing Inc. is on the hunt for innovative minds to join our team as Data Engineers!\n",
            "\n",
            "**We're excited to announce that we're now accepting applications from both experienced professionals and fresh graduates!**\n",
            "\n",
            "As a Data Engineer at Marketing Inc., you'll have the opportunity to:\n",
            "- Work with cutting-edge technology and massive datasets 🖥\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "louHDw4yuHP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ANsFddafsN1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dNm7lAILtlUz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZFH8FP9S7APrhQueECXaG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}